# I/O Bound Application - 스레드 모델 학습 정리

## 1. Thread-Per-Task 모델 (CachedThreadPool)

> `IoBoundApplication.java`

- `Executors.newCachedThreadPool()`을 사용하여 작업마다 새 스레드를 생성하는 방식
- 1초짜리 블로킹 I/O 작업 **1,000개**를 약 **1초**에 완료 (높은 병렬성)
- 하지만 작업을 **10,000개**로 늘리면 크래시 발생:
  ```
  unable to create native thread: possibly out of memory or process/resource limits reached
  ```

### 문제점
- 작업 수만큼 스레드를 무제한 생성하므로 시스템 자원 한계에 도달

---

## 2. FixedThreadPool을 이용한 해결 및 컨텍스트 스위칭 비용

> `IoBoundApplicationV2.java`

- `Executors.newFixedThreadPool(1000)`으로 스레드 수를 **1,000개로 고정**
- **10,000개** 작업을 에러 없이 약 **10초**에 완료

### 스레드의 비용
| 상황 | 결과 |
|------|------|
| 스레드가 너무 많으면 | 애플리케이션 크래시 |
| 스레드가 너무 적으면 | 처리량과 CPU 활용률 저하 |

- 스레드는 **스택 메모리**와 기타 자원을 소비한다
- 생성할 수 있는 스레드 수는 **제한**되어 있다

### 컨텍스트 스위칭의 비용
- OS는 CPU를 최대한 활용하려 하며, 블로킹 호출이 발생하면 즉시 해당 스레드의 스케줄을 해제한다
- 스레드가 너무 많고 블로킹 호출이 잦으면 → CPU가 **OS 코드 실행에 바빠짐**
- **스레드 스래싱(Thread Thrashing)**: CPU 대부분이 실제 작업이 아닌 OS의 스레드 관리에 소비되는 현상

### 스래싱 실험 (`blockingIoOperationV2`)
- 10ms sleep x 100회 = 총 1초의 블로킹이지만, 실제로는 **1초보다 훨씬 오래 걸림**
- 빈번한 블로킹 → 빈번한 컨텍스트 스위칭 → 성능 저하

---

## 핵심 정리

- **Thread-Per-Task** 모델은 수십 년간 표준으로 사용되었지만, **최적의 성능과 CPU 활용률을 제공하지 못한다**
- CachedThreadPool은 소규모 작업에 적합하지만 **대규모 작업에서는 자원 한계에 도달**
- FixedThreadPool로 스레드 수를 제한하면 안정성은 확보되지만, **컨텍스트 스위칭 오버헤드** 문제가 남아있다
- 이러한 한계를 극복하기 위해 **Virtual Thread** 등 새로운 동시성 모델이 등장

## 3. 논블로킹 I/O

Thread-Per-Task 모델의 한계를 극복하기 위한 대안으로, **코어당 스레드(Thread-Per-Core)** 모델과 함께 사용할 수 있다.

### 장점
- **성능 향상** - 블로킹 없이 I/O 작업을 처리하므로 처리량이 높아진다
- **컨텍스트 스위칭 최소화** - 스레드 수가 코어 수에 맞춰져 불필요한 전환이 줄어든다
- **메모리 오버헤드 감소** - 적은 수의 스레드로 많은 작업을 처리할 수 있다
- **시스템 안정성 향상** - 스레드 폭증으로 인한 크래시 위험이 없다

### 단점
- 코드 작성, 읽기, 테스트 및 디버깅이 **어렵다**
- 외부 프레임워크 및 라이브러리에 대한 **의존성**이 생긴다 (e.g. Netty, Reactor)